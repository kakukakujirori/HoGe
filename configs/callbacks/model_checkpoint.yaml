# https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.ModelCheckpoint.html
# NOTE: The most important metric must come first, as it is used as the best metric to retrieve the checkpoint for testing.

# model_checkpoint_miou:
#   _target_: lightning.pytorch.callbacks.ModelCheckpoint
#   dirpath: ${paths.output_dir}/checkpoints/ # directory to save the model file
#   filename: epoch={epoch:03d}_miou={val/miou:.3f} # checkpoint filename
#   monitor: val/miou # name of the logged metric which determines when model is improving
#   verbose: false # verbosity mode
#   save_last: false # additionally always save an exact copy of the last checkpoint to a file last.ckpt
#   save_top_k: 1 # save k best models (determined by above metric)
#   mode: max # “max” means higher metric value is better, can be also “min”
#   auto_insert_metric_name: false # when True, the checkpoints filenames will contain the metric name
#   save_weights_only: false # if True, then only the model’s weights will be saved
#   every_n_train_steps: null # number of training steps between checkpoints
#   train_time_interval: null # checkpoints are monitored at the specified time interval
#   every_n_epochs: null # number of epochs between checkpoints
#   save_on_train_epoch_end: null # whether to run checkpointing at the end of the training epoch or the end of validation

# model_checkpoint_fscore:
#   _target_: lightning.pytorch.callbacks.ModelCheckpoint
#   dirpath: ${paths.output_dir}/checkpoints/ # directory to save the model file
#   filename: epoch={epoch:03d}_fscore={val/fscore:.3f} # checkpoint filename
#   monitor: val/fscore # name of the logged metric which determines when model is improving
#   verbose: false # verbosity mode
#   save_last: false # additionally always save an exact copy of the last checkpoint to a file last.ckpt
#   save_top_k: 1 # save k best models (determined by above metric)
#   mode: max # “max” means higher metric value is better, can be also “min”
#   auto_insert_metric_name: false # when True, the checkpoints filenames will contain the metric name
#   save_weights_only: false # if True, then only the model’s weights will be saved
#   every_n_train_steps: null # number of training steps between checkpoints
#   train_time_interval: null # checkpoints are monitored at the specified time interval
#   every_n_epochs: null # number of epochs between checkpoints
#   save_on_train_epoch_end: null # whether to run checkpointing at the end of the training epoch or the end of validation

model_checkpoint_total_loss:
  _target_: lightning.pytorch.callbacks.ModelCheckpoint
  dirpath: ${paths.output_dir}/checkpoints/ # directory to save the model file
  filename: epoch={epoch:03d}_loss={val/total_loss:.3f} # checkpoint filename
  monitor: val/total_loss # name of the logged metric which determines when model is improving
  verbose: false # verbosity mode
  save_last: true # additionally always save an exact copy of the last checkpoint to a file last.ckpt
  save_top_k: 1 # save k best models (determined by above metric)
  mode: min # “max” means higher metric value is better, can be also “min”
  auto_insert_metric_name: false # when True, the checkpoints filenames will contain the metric name
  save_weights_only: false # if True, then only the model’s weights will be saved
  every_n_train_steps: null # number of training steps between checkpoints
  train_time_interval: null # checkpoints are monitored at the specified time interval
  every_n_epochs: null # number of epochs between checkpoints
  save_on_train_epoch_end: null # whether to run checkpointing at the end of the training epoch or the end of validation
